1. Set up the environment:
   a. Install Python, if not already installed: https://www.python.org/downloads/.
   b. Install an Integrated Development Environment (IDE) (optional, but recommended): Some popular options are VSCode, PyCharm, and Jupyter Notebook.

2. Install the necessary libraries:
   a. Install Natural Language Toolkit (nltk) for text preprocessing: `pip install nltk`
   b. Install scikit-learn for machine learning algorithms: `pip install scikit-learn`
   c. Install the Gensim library for working with pre-trained word embeddings: `pip install gensim`
   d. Optional: Install any other desired NLP libraries like spaCy, TextBlob, or BERT.

3. Define the file scanning and reading functions:
   a. Import the necessary modules: os, nltk, glob, and re.
   b. Write a function to read the contents of a file.
   c. Write a function to scan the target directory for txt files.

4. Preprocessing:
   a. Import nltk functions: word_tokenize, stopwords, and WordNetLemmatizer.
   b. Write a function to clean and preprocess the text data:
      - Tokenize the text
      - Convert text to lowercase
      - Remove punctuation and special characters
      - Remove stopwords
      - Lemmatize words
   c. Preprocess each text file's content and save in a list.

5. Feature extraction:
   a. Use Gensim's Word2Vec or other pretrained word embeddings like GloVe or fastText to represent words as vectors.
   b. Write a function to vectorize text data using the pre-trained word embeddings.
   c. Transform the preprocessed text data into feature vectors.

6. Determine the best similarity measure:
   a. Study similarity measures like: cosine, Jaccard, Euclidean, or Pearson.
   b. Choose the most appropriate similarity measure for this task.

7. Cluster analysis:
   a. Decide on the clustering algorithm that best suits the project requirements (e.g., K-Means, DBSCAN, Agglomerative Clustering, etc.).
   b. Write a function that automatically determines the optimal number of clusters.
   c. Implement the clustering algorithm, considering the optimal number of clusters.

8. Categorize the txt files based on similarity:
   a. Assign each text file to its corresponding cluster.
   b. Save the clustering results into a convenient format (dictionary, CSV, etc.).

9. Test the program
   a. Create a test directory.
   b. Add some txt files to the test directory.
   c. Run the program on this test directory.
   d. Evaluate the results and improve the model as needed.

10. Optional: Implement a user interface
    a. Create a GUI or a web interface for users to easily use the program.